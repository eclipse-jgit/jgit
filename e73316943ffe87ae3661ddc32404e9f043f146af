{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "481e4186_884ea43c",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 5
      },
      "lineNbr": 0,
      "author": {
        "id": 1015244
      },
      "writtenOn": "2025-01-23T14:09:18Z",
      "side": 1,
      "message": "@matthias.sohn@sap.com I believe this issue I am working on is somewhat related [1]\n\nWhen having a highly concurrent load (r/w) against a Gerrit on reftable with external GC processes scheduled, we found that `BlockSource` endup pointing to stale reftable resources.\n\nThe plan is check explicitly before attempting a read and then handle the exception appropriately (i.e. triggering a refresh/reload, similarly to what you do here).\n\n[1] https://eclipse.gerrithub.io/c/eclipse-jgit/jgit/+/1206693",
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "7dc76068_c27dbc90",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 5
      },
      "lineNbr": 0,
      "author": {
        "id": 1000000
      },
      "writtenOn": "2025-01-27T15:40:32Z",
      "side": 1,
      "message": "FYI, I\u0027ve raised a Gerrit bug where the reference counting diverges and repositories won\u0027t be closed. Fixing it, would solve the ref-table issue. See https://issues.gerritcodereview.com/issues/392541994",
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "fe57f35b_1b687f7b",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 5
      },
      "lineNbr": 0,
      "author": {
        "id": 1000000
      },
      "writtenOn": "2025-01-27T15:40:32Z",
      "side": 1,
      "message": "FYI, I\u0027ve raised a Gerrit bug where the reference counting diverges and repositories won\u0027t be closed. Fixing it, would solve the ref-table issue",
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "518f9f36_0ba8baf8",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/file/FileReftableDatabase.java",
        "patchSetId": 5
      },
      "lineNbr": 191,
      "author": {
        "id": 1000000
      },
      "writtenOn": "2025-01-23T13:37:40Z",
      "side": 1,
      "message": "I\u0027m not sure this is enough: the ref-table on disk may change after L191 during the execution of L192, and we may be returning the wrong outdated values or making an exception.\n\nI believe the correct structure should be a while/loop where:\n1. The reloadIfNecessary() should return a timestamp (or snapshot) S1\n2. We execute the body between L192 and L196\n3. We re-run reloadIfNecessary() and get the new timestamp (or snapshot) S2\n4. whilst S2 \u003c\u003e S1, we execute the loop again",
      "range": {
        "startLine": 191,
        "startChar": 2,
        "endLine": 191,
        "endChar": 21
      },
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "5c7fe6c6_7b3c9eb1",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/file/FileReftableDatabase.java",
        "patchSetId": 5
      },
      "lineNbr": 191,
      "author": {
        "id": 1038403
      },
      "writtenOn": "2025-01-24T18:18:50Z",
      "side": 1,
      "message": "I would say that looping should only happen on exceptions (when a result cannot be read), not because the files(ref) have changed after line 191. While it is true, that an out-of-date result may be returned, that is true no matter how much you loop, even once the files appear to no longer change (they can always change again after your check). What matters is not that the latest result is always returned (that is impossible), but that the result returned was accurate at least for a moment in time after the method call started. Therefore, I think it is wrong to be rechecking timestamps at the end unless we are trying to determine that a detected error condition (such as a caught exception) might have been caused by a change.",
      "parentUuid": "518f9f36_0ba8baf8",
      "range": {
        "startLine": 191,
        "startChar": 2,
        "endLine": 191,
        "endChar": 21
      },
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "407e8cef_ff7f341a",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/file/FileReftableDatabase.java",
        "patchSetId": 5
      },
      "lineNbr": 191,
      "author": {
        "id": 1000000
      },
      "writtenOn": "2025-01-24T21:58:27Z",
      "side": 1,
      "message": "\u003e I would say that looping should only happen on exceptions (when a result cannot be read), not because the files(ref) have changed after line 191. While it is true, that an out-of-date result may be returned,\n\nIt could be actually worse: if we are in a racy situation, then the data may be changing *whilst* we read and therefore the results may be inconsistent or, as you\u0027ve rightly pointed out, even cause exceptions.\n\nWe do the racy loop in PackDirectory.getPacks()\n\n```\ndo {\n\tlist \u003d packList.get();\n\tif (list \u003d\u003d NO_PACKS) {\n\t\tlist \u003d scanPacks(list);\n\t}\n} while (searchPacksAgain(list));\n```\n\n\u003e that is true no matter how much you loop, even once the files appear to no longer change (they can always change again after your check).\n\nTrue, but at least we know that *at the point of the return* the data was stable and did not change between the start and the end of the method.\nIf the data on disk is different on the start than at the end of the method, the read is definitely racy.\n\nSee the relevant discussion and presentation by Matthias many years ago at the Gerrit User Summit (https://youtu.be/m44cAozuLNI).\n\n\u003e What matters is not that the latest result is always returned (that is impossible), but that the result returned was accurate at least for a moment in time after the method call started.\n\nI respectfully disagree: it must be *consistent* and up-to-date to when the method ended. If the data on disk is changing, my read could be inconsistent, even there are no exception thrown.",
      "parentUuid": "5c7fe6c6_7b3c9eb1",
      "range": {
        "startLine": 191,
        "startChar": 2,
        "endLine": 191,
        "endChar": 21
      },
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "08a2217f_c59c4f1b",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/file/FileReftableDatabase.java",
        "patchSetId": 5
      },
      "lineNbr": 191,
      "author": {
        "id": 1038403
      },
      "writtenOn": "2025-01-24T22:03:59Z",
      "side": 1,
      "message": "\u003e it must be consistent and up-to-date to when the method ended. If the data on disk is changing, my read could be inconsistent, even there are no exception thrown.\n\nI agree with this. I do believe that the design of the tables helps ensure this. RefTable files are immutable, so the data within an individual table file cannot change. The only thing that can change the view is the table list, and the existence of RefTable files. Once the file list is read, if the tables are looked up in the order of the list, and no tables are missed, the view should be guaranteed to be consistent with the original list.",
      "parentUuid": "407e8cef_ff7f341a",
      "range": {
        "startLine": 191,
        "startChar": 2,
        "endLine": 191,
        "endChar": 21
      },
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "5dcfce33_ea8ab3ab",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/file/FileReftableDatabase.java",
        "patchSetId": 5
      },
      "lineNbr": 191,
      "author": {
        "id": 1000671
      },
      "writtenOn": "2025-01-27T09:17:05Z",
      "side": 1,
      "message": "yep, I think reading a stack of reftables always returns a consistent result.\n\nReftable files are immutable, the stack of reftable files (`FileReftableStack`) considered in reads is based on the list of reftable file names stored in the `tables.list` file. Updates of this file are guarded by a FileLock, the new content is written to a temporary file and transactions are committed by atomically renaming the `tables.list` file.\n\nUnless we enforce pessimistic locking of all refs, a reftable stack, representing a consistent view on all refs, can be outdated anytime after we started reading it.\nRef updates add another reftable, the corresponding new reftable file name is added to the `tables.list` file using a transactional update as explained above. Updating refs should fail if the view of refs the update is based on, is found to be stale during the update.",
      "parentUuid": "08a2217f_c59c4f1b",
      "range": {
        "startLine": 191,
        "startChar": 2,
        "endLine": 191,
        "endChar": 21
      },
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b2c45203_c40ad7e6",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/file/FileReftableDatabase.java",
        "patchSetId": 5
      },
      "lineNbr": 191,
      "author": {
        "id": 1000000
      },
      "writtenOn": "2025-01-27T10:07:23Z",
      "side": 1,
      "message": "\u003e yep, I think reading a stack of reftables always returns a consistent result.\n\u003e \n\u003e Reftable files are immutable, the stack of reftable files (`FileReftableStack`) considered in reads is based on the list of reftable file names stored in the `tables.list` file. Updates of this file are guarded by a FileLock, the new content is written to a temporary file and transactions are committed by atomically renaming the `tables.list` file.\n\nYes, there is an issue in the auto-compaction though: the specs (https://git-scm.com/docs/reftable#_compaction) say that _\"Delete B and C, perhaps after a short sleep to avoid forcing readers to backtrack.\"_ whilst at the moment they happen immediately.\n\nSo, even if you are reading the `tables.list` and checking that all the files exist, then another thread may perform the deletion of compacted files and you may fail to get your consistent read.\n\nThat is possibly something we need to address in the auto-compaction algorithm and doing something like the _\"preserved\"_ directory for files to be removed later on.\n\n\u003e Unless we enforce pessimistic locking of all refs, a reftable stack, representing a consistent view on all refs, can be outdated anytime after we started reading it.\n\nYes and agreed: we don\u0027t care about the data read to be stale, as you can *always* be stale compared with what is on disk at any time after the read.\n\nIf the subsequent update on the reftable which was based on stale data detects the staleness, it will then fail and cause the whole transaction to be retried, as @hanwenn@gmail.com properly tested in the `FileReftableTest.testRacyReload()`. \n\nP.S. I believe we *should keep* that test and make sure we don\u0027t break it, as it represent one design principle of the ref-table about consistent snapshots and consistent updates.",
      "parentUuid": "5dcfce33_ea8ab3ab",
      "range": {
        "startLine": 191,
        "startChar": 2,
        "endLine": 191,
        "endChar": 21
      },
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b6dda413_6ab97a02",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/file/FileReftableDatabase.java",
        "patchSetId": 5
      },
      "lineNbr": 191,
      "author": {
        "id": 1007980
      },
      "writtenOn": "2025-01-27T11:07:40Z",
      "side": 1,
      "message": "Any write (including compaction) causes tables.list and/or the tables to be outdated. But this is usually not the case, because writes happen less frequently than reads. If you write as often as you read, You\u0027re Gonna Have a Bad Time whatever you do.\n\n\u003e and cause the whole transaction to be retried,\n\nno, this is up to the caller. The caller may also give up.\n\nI think the reporter for the bug would be happy if something in Eclipse would reload the ref based on some sort of file notification on `tables.list`. I can\u0027t judge if this appropriate to add to JGit though. \n\n\u003e\"Delete B and C, perhaps after a short sleep to avoid forcing readers to backtrack.\n\nI did not implement this, because it requires hooking up the RefDB to some sort of thread-executor to schedule the background work.",
      "parentUuid": "b2c45203_c40ad7e6",
      "range": {
        "startLine": 191,
        "startChar": 2,
        "endLine": 191,
        "endChar": 21
      },
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "362f4328_f9574271",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/file/FileReftableDatabase.java",
        "patchSetId": 5
      },
      "lineNbr": 191,
      "author": {
        "id": 1000000
      },
      "writtenOn": "2025-01-27T11:39:21Z",
      "side": 1,
      "message": "\u003e Any write (including compaction) causes tables.list and/or the tables to be outdated. But this is usually not the case, because writes happen less frequently than reads.\n\nWith NoteDb, in my experience with CI/CD Bots and AI tools with customers, the draft comments, reviews, scores and messages on the changes are making the refs updated *very frequently*. The `packed-refs` was always constantly locked.\n\nAlso, with the adoption of mono-repos, reviews and activities on separate projects that are hosted on the same repository compete to lock the same `packed-refs` file.\n\nNow, with ref-table, my worry is that we have a similar problem if we try to lock the `tables.list`.\n\n\u003e If you write as often as you read, You\u0027re Gonna Have a Bad Time whatever you do.\n\u003e and cause the whole transaction to be retried,\n\nYes, I see this happening in my initial tests, where I simulate _customer-like_ traffic using Gatling tests with hundreds of users working on the same repository.\n\n\u003e no, this is up to the caller. The caller may also give up.\n\nGerrit also has an internal _retry helper_ that does the retry _on behalf_ of the client.\n\n\u003e I think the reporter for the bug would be happy if something in Eclipse would reload the ref based on some sort of file notification on `tables.list`. I can\u0027t judge if this appropriate to add to JGit though. \n\nI believe it should be done at higher level in the EGit plugin rather than in JGit.\nSimilarly, it should be done at Gerrit level rather than in JGit.\n\nThe higher application level *knows* the boundaries of the transaction that is willing to perform, therefore it can decide on the window of _consistency_ that is needed to complete it.\n\n\u003e \u003e\"Delete B and C, perhaps after a short sleep to avoid forcing readers to backtrack.\n\u003e \n\u003e I did not implement this, because it requires hooking up the RefDB to some sort of thread-executor to schedule the background work.\n\nYes, I believe that\u0027s just another feature to be added: thanks for the work you\u0027ve done so far, maybe we can take this onboard and add it to the JGit\u0027s ref-table implementation.",
      "parentUuid": "b6dda413_6ab97a02",
      "range": {
        "startLine": 191,
        "startChar": 2,
        "endLine": 191,
        "endChar": 21
      },
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "48abf3f4_8a120d1c",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/file/FileReftableDatabase.java",
        "patchSetId": 5
      },
      "lineNbr": 191,
      "author": {
        "id": 1038403
      },
      "writtenOn": "2025-01-27T17:15:54Z",
      "side": 1,
      "message": "\u003e With NoteDb, in my experience with CI/CD Bots and AI tools with customers, the draft comments, reviews, scores and messages on the changes are making the refs updated *very frequently*. The `packed-refs` was always constantly locked.\n\u003e \n\u003e Also, with the adoption of mono-repos, reviews and activities on separate projects that are hosted on the same repository compete to lock the same `packed-refs` file.\n\u003e \n\u003e Now, with ref-table, my worry is that we have a similar problem if we try to lock the `tables.list`.\n\n\nHopefully this not be a problem. Although in theory, re-tables should actually lock the main point of contention, \"tables.list\", more often than the packed-refs file, the lock durations should be way shorter, especially when comparing to large packed-refs files (the ones the most likely to updated frequently). That means, that we may want to tweak retry times in applications such a Gerrit when using reftables, we may want the retry wait times to be much shorter. Shorter retry wait times should increase write throughput.\n\n\u003e \u003e \u003e\"Delete B and C, perhaps after a short sleep to avoid forcing readers to backtrack.\n\u003e \u003e \n\u003e \u003e I did not implement this, because it requires hooking up the RefDB to some sort of thread-executor to schedule the background work.\n\nThis could potentially be also addressed via \"preserved\" tables. Allow the deletion of normal compacted tables to be synchronous, and make readers smart enough to look for the preserved files even if they did not already have the non preserved version open. This could allow reads to avoid starting completely over and increase read throughput on servers with heavy writes.",
      "parentUuid": "362f4328_f9574271",
      "range": {
        "startLine": 191,
        "startChar": 2,
        "endLine": 191,
        "endChar": 21
      },
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "2541c5da_5d77fec7",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/file/FileReftableDatabase.java",
        "patchSetId": 5
      },
      "lineNbr": 191,
      "author": {
        "id": 1000000
      },
      "writtenOn": "2025-01-30T17:42:57Z",
      "side": 1,
      "message": "\u003e \u003e Now, with ref-table, my worry is that we have a similar problem if we try to lock the `tables.list`.\n\u003e \n\u003e \n\u003e Hopefully this not be a problem. Although in theory, re-tables should actually lock the main point of contention, \"tables.list\", more often than the packed-refs file, the lock durations should be way shorter, especially when comparing to large packed-refs files (the ones the most likely to updated frequently). \n\nYes, agreed. It is very unlikely for a Gerrit site to have thousands of lines in the `tables.list` file, therefore the contention would not last for long.\n\n\u003e That means, that we may want to tweak retry times in applications such a Gerrit when using reftables, we may want the retry wait times to be much shorter. Shorter retry wait times should increase write throughput.\n\nYep.\n\n\u003e \u003e \u003e I did not implement this, because it requires hooking up the RefDB to some sort of thread-executor to schedule the background work.\n\u003e \n\u003e This could potentially be also addressed via \"preserved\" tables. Allow the deletion of normal compacted tables to be synchronous, and make readers smart enough to look for the preserved files even if they did not already have the non preserved version open. This could allow reads to avoid starting completely over and increase read throughput on servers with heavy writes.\n\nSure, that would work because even if the file is not in its location, the actual content and inode is still there but with a different name. It would also work nicely over NFS avoiding the stale file handle problem upon physical deletions.",
      "parentUuid": "48abf3f4_8a120d1c",
      "range": {
        "startLine": 191,
        "startChar": 2,
        "endLine": 191,
        "endChar": 21
      },
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "1b39c471_403635ca",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/file/FileReftableDatabase.java",
        "patchSetId": 5
      },
      "lineNbr": 191,
      "author": {
        "id": 1000671
      },
      "writtenOn": "2025-01-31T22:54:45Z",
      "side": 1,
      "message": "Can we move the discussion about the problem with compaction to an issue ?\nIt seems to go beyond the scope of this change.",
      "parentUuid": "2541c5da_5d77fec7",
      "range": {
        "startLine": 191,
        "startChar": 2,
        "endLine": 191,
        "endChar": 21
      },
      "revId": "e73316943ffe87ae3661ddc32404e9f043f146af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    }
  ]
}